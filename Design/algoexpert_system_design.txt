AlgoExpert System Design Fundamentals


3. Client Server Model: 

        Lets look at an example
        
        Client: browser 
            - DNS: 
                - IP

        
        Server: AlgoExpert backend

        Client: A machine or process that requests data or service from a server

        Node: a single machine can be both the client and a server at the same times

        IP address: an address given to each machine connected the public internet. IPV4 address consists of four numbers seperated by dots.  where all 4 values are from 0 - 255

        In order for multiple programs to listen for a new network connection without colliding, they pick a port:
            here are some predefined example ports:
                22: Secure Shell
                53: DNS lookup
                80: http
                443: HTTPS 


4. Network protocols: 
    IP: Internet Protocol address
        - IP packet: data sent from one machine to another
        - IP address: a unique address given to each machine connected to the public internet
        - IP packets: are made up of bytes

    TCP: Transmission Control Protocol
        - built on top of the IP
        - send IP packets in an ordered way
        - allows you to send arbitrarily large pieces of data

    HTTP: 
        - Hypertext Transfer Protocol
        - Built on top of TCP
        - introduces higher level of abstraction on top of TCP and IP
        - basically a way of communicating in a request and response paradigm
        - HTTP is a request/response protocol that is much more applicable in sys design questions.

5. Storage

        - Database 
            - write data
            - read dat
            - just a server
            
            - You can write data to: 
                - disk: to a physical hard drive
                - memory: data is stored in memory pros because it is faster to access but if it goes down, it will be lost


6. Latency and Throughput 
    - 2 most important measure of the performance of a System
        - Latency: how long it takes to send a packet
        - Throughput: how much data can be sent in a given amount of time

    Latency:
        - if you are reading 1MB sequentially of data in 1 second from memory, that takes 250 microseconds
        - if you are reading 1MB sequentially of data in 1 second from SSD, that takes 1000 microseconds
        - if you are sending 1MB sequentially of data in 1GB/second network, that takes 10k microseconds
        - if you are sending 1MB sequentially of data in HDD, that takes 20k microseconds
        - if you are sending a packet (smaller than 1MB ) sequentially from Cali to Neth, to Cali, that takes 150k microseconds

    Throughput:
        - if you are reading 1MB sequentially of data in 1 second from memory, that takes 250 microseconds-
    
    - examples:
        - video games: those systems can have fast connection or slow(lag) because of how far a server is
    - in  sys design, we need to understand the tradeoff


    - How to handle throughput: 
        (naive)
        - you can pay your server provider to "increase" throughput
        
        (better)
        - have multiple servers handling the request

    - you can't make assumpstions on latency & throughput based on the other, they are not necessary correlated 

    
6. Availability 
    - when dealing with availability, we are dealing with high percentages
    - in the industry, we use 9's to use availability. so like if we had 99.99% availability, we would say 4 9's 
    - 5 9's is the gold standard of availability

    Service providers have a SLA 
    - SLA: Service Level Agreement
    - customers agree to their SLA when using their service, as you can see in like namecheap they guarentee 99.99% availability
    - SLO: Service Level Objective which is components of SLA.

    During system design interviews:
        - what part of the system requires high availability and what can use less availability

    How do we improve the availability of our system:
        - system doesn't have single points of failure (solve with redundancy)
        - have load-balancers to distribute traffic
        

7. Caching
    - Caching is used to reduce redundancy in our system.
    - caching is helpful when you have computational long  running tasks that take a long time to complete
    - you are able to client side or server side cache the data in order to speed up access to data
    - if you don't need frequent access to data, you can cache it.


    - you can actually call your db to update cache to server side cache then you won't have to hit db when client hits server

    - Writeback cache:
        - 


